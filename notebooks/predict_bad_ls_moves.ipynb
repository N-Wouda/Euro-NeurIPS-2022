{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict bad LS moves\n",
    "\n",
    "This notebook develops simple models for predicting bad local search moves. Particularly, given nodes $U$ and $V$ in routes $R_U$ and $R_V$, it predicts whether each LS operator we currently have is likely to produce an improving solution if the operator were applied to these node pairs $U$ and $V$.\n",
    "\n",
    "The motivation is that evaluating a full operator move is typically somewhat slow, whereas a fast and reasonably accurate prediction method can completely avoid such evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\Python\\Euro-NeurIPS-2022\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from glob import iglob\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data/raw/\")\n",
    "INST_PATH = Path(\"instances/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "These can be used to quickly parse the raw results for a single instance into something that contains the same data, but in a more workable format. Uses a generator, so the memory overhead is minimal. Also provides some utilities to work with these generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked_iterable(iterable, size):\n",
    "    \"After https://alexwlchan.net/2018/12/iterating-in-fixed-size-chunks/\"\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, size))\n",
    "        if not chunk:\n",
    "            break\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Record:\n",
    "    op: int\n",
    "    U: int\n",
    "    V: int\n",
    "    delta: int\n",
    "    Ru: list[int]\n",
    "    Rv: list[int]\n",
    "\n",
    "def parse_file(file: str):\n",
    "    def parse_record(record: list[str]) -> Record:\n",
    "        op = int(record[0].strip())\n",
    "        U, V, delta = map(int, record[1].strip().split(\" \"))\n",
    "        _, *Ru = map(int, re.findall('[0-9]+', record[2].strip()))\n",
    "        _, *Rv = map(int, re.findall('[0-9]+', record[3].strip()))\n",
    "\n",
    "        return Record(op, U, V, delta, Ru, Rv)\n",
    "\n",
    "    with open(file, 'r') as fh:\n",
    "        args = [iter(fh)] * 4\n",
    "        records = zip(*args)\n",
    "\n",
    "        yield from chunked_iterable(map(parse_record, records), 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(instance, records):\n",
    "    dist = instance['duration_matrix']\n",
    "    dist_max = dist.max()\n",
    "    data = []\n",
    "    \n",
    "    for record in records:\n",
    "        dist_uv = dist[record.V, record.U] / dist_max\n",
    "        dist_vu = dist[record.U, record.V] / dist_max\n",
    "        \n",
    "        data.append([dist_uv, dist_vu])\n",
    "    \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = tools.read_vrplib(INST_PATH / 'ORTEC-VRPTW-ASYM-1de83915-d1-n262-k15.txt')\n",
    "\n",
    "# record = next(parse_file(DATA_PATH / 'ORTEC-VRPTW-ASYM-1de83915-d1-n262-k15.txt'))\n",
    "# make_features(instance, record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = tools.read_vrplib(INST_PATH / 'ORTEC-VRPTW-ASYM-1de83915-d1-n262-k15.txt')\n",
    "\n",
    "for records in parse_file(DATA_PATH / 'ORTEC-VRPTW-ASYM-1de83915-d1-n262-k15.txt'):\n",
    "    y = [int(record.delta < 0) for record in records]\n",
    "    X = make_features(instance, records)\n",
    "    model.partial_fit(X, y, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for records in parse_file(DATA_PATH / 'ORTEC-VRPTW-ASYM-1de83915-d1-n262-k15.txt'):\n",
    "#     y = [int(record.delta < 0) for record in records]\n",
    "#     X = make_features(instance, records)\n",
    "    \n",
    "#     print(model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
